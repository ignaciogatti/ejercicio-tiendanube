{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores\n",
    "\n",
    "Esta notebook contiene la definición, entrenamiento y evaluación de una serie de clasificadores cuyo objetivo es predecir cuales de los *usuarios trials* se van a convertir en *payments*.\n",
    "\n",
    "Básicamente, se tiene un dataset con dos clases: una **positiva** (*usuarios trials* que se convirtieron en *payments*) y una **negativa** (*usuarios trials* que **no** se convirtieron en *payments*).\n",
    "\n",
    "Una vez entrenados los modelos, éstos se evaluan a la luz de una serie de métricas con el fin de poder determinar cuál de ellos posee un mejor desempeño para realizar la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para decidir que dataset se va a utilizar\n",
    "def get_configuracion(balanceado):\n",
    "    \n",
    "    if balanceado:\n",
    "        return {\n",
    "            'path': 'dataset_balanceado.csv',\n",
    "            'class_weight' : None,\n",
    "            'tipo' : 'balanceado'\n",
    "        }\n",
    "    else:\n",
    "        return{\n",
    "            'path': 'dataset_desbalanceado.csv',\n",
    "            'class_weight' : 'balanced',\n",
    "            'tipo' : 'desbalanceado'\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trabaja con dos tipos de dataset con el fin de observar cómo impactan en el entrenamiento de los modelos. Uno de ellos está **balanceado** y el otro **desbalanceado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuracion_desbalanceada = get_configuracion(False)\n",
    "configuracion_balanceada = get_configuracion(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_balanceada = pd.read_csv(configuracion_balanceada['path'])\n",
    "df_data_desbalanceada = pd.read_csv(configuracion_desbalanceada['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se chequea que se hayan cargado los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_balanceada.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset entrenamiento y test\n",
    "\n",
    "A continuación se define una función que divide el dataset en dos: uno para entrenamiento del modelo y otro para la evaluación del mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_dataset(df_data):\n",
    "    y = df_data['target']\n",
    "    X = df_data.drop(columns=['target'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "A continuación se entrenan una serie de algoritmos de clasificación. Se tomaron alguno de los alogritmos clásicos en la literatura, tales como *Nearest Neighbors* y *RBF SVM*; y otros que, si bien hoy en día son clásicos, se los puede catalogar dentro de los algoritmos de clasificación que se encuentran más cercano al estado del arte, tales como  *Random Forest*, *Neural Net*, *AdaBoost*.\n",
    "\n",
    "Los primeros sirven como *baseline* y el objetivo de los otros es superar el rendimiento de los primeros.\n",
    "\n",
    "Dado que se tiene dos tipos de dataset, se entranarán todos los modelos con ambos con el fin de observar el impacto que produce el desbalance sobre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clasificadores(configuracion):\n",
    "\n",
    "    names = ['Nearest Neighbors', 'RBF SVM', 'Random Forest', 'Neural Net', 'AdaBoost']\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(gamma=2, C=1, class_weight=configuracion['class_weight']),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, class_weight=configuracion['class_weight']),\n",
    "        MLPClassifier(max_iter=1000),\n",
    "        AdaBoostClassifier()\n",
    "    ]\n",
    "    \n",
    "    return names, classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset balanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los dataset de *entrenamiento* y *test* así como los modelos para trabajar con el dataset balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = get_train_test_dataset(df_data_balanceada)\n",
    "names_bal, classifiers_bal =get_clasificadores(configuracion_balanceada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenan los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento de los modelos\n",
    "for name, clf in zip(names_bal, classifiers_bal):\n",
    "    clf.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset desbalanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define los dataset de *entrenamiento* y *test* así como los modelos para trabajar con el dataset desbalanceado. En este caso, a los modelos *SVC* y *Random Forest* se les *setea* la propiedad **class_weight** con el fin de que presten más atención a la clase con menor cantidad de instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_des, X_test_des, y_train_des, y_test_des = get_train_test_dataset(df_data_desbalanceada)\n",
    "names_des, classifiers_des =get_clasificadores(configuracion_desbalanceada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenan los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento de los modelos\n",
    "for name, clf in zip(names_des, classifiers_des):\n",
    "    clf.fit(X_train_des, y_train_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de los modelos\n",
    "\n",
    "Dado que se esta trabajando sobre un dataset desbalanceado, para la evaluación de los modelos se analizan las siguientes métricas que son las más utilizadas en la literatura para estos escenarios:\n",
    "\n",
    "* **Curva ROC** que muestra la razón o proporción de *verdaderos positivos* (VPR = Razón de Verdaderos Positivos) frente a la razón o proporción de *falsos positivos* (FPR = Razón de Falsos Positivos).\n",
    "* **Curva de Precision-recall** que muetra la relación que existe entre las métricas *precision* y *recall* para diferentes umbrales. La *precisión* se define como a la fracción de instancias recuperadas que son relevantes; mientras que el *recall* es la fracción de instancias relevantes que han sido recuperadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plots(names, classifiers, axs, X_test, y_test, tipo_dataset ):\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "\n",
    "        plot_roc_curve(clf, X_test, y_test, ax=axs[0], name=name)\n",
    "        plot_precision_recall_curve(clf, X_test, y_test, ax=axs[1], name=name)\n",
    "        \n",
    "    axs[0].set_title('Curva ROC - ' + tipo_dataset)\n",
    "    axs[1].set_title('Curva de precision-recall - ' + tipo_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Defino los graficos a mostrar\n",
    "fig, [ax_bal, ax_des] = plt.subplots(2, 2, figsize=(14, 10))\n",
    "#Calculo la curva para los modelos entrenados con el dataset balanceado\n",
    "get_plots(names_bal, classifiers_bal, ax_bal, X_test_bal, y_test_bal, 'Dataset Balanceado')\n",
    "#Calculo la curva para los modelos entrenados con el dataset desbalanceado\n",
    "get_plots(names_des, classifiers_des, ax_des, X_test_des, y_test_des, 'Dataset Desbalanceado')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados reportados es posible derivar las siguientes conclusiones:\n",
    "\n",
    "* Si uno se centra en la **curva ROC** observará que los modelos parecerían no estar influenciados por dicho desbalance (de hecho, muestran un rendimiento prácticamente análogo). Esto se debe a que en la **curva ROC** no hace énfasis sobre la clase postiva, que es la menos representada en el dataset y, a su vez, la que nos interesa detectar. Por eso hay que poner el foco sobre la **curva de precision-recall**. Allí se observará que los modelos entrenados con el dataset **desbalanceado** tienen un desempeño pobre a la hora de distinguir una clase de la otra (principalmente a la hora de detectar la clase positiva); mientras que los mismos modelos entrenados con un dataset **balanceado** ofrecen un aceptable rendimiento (por encima del 75%).\n",
    "\n",
    "* Si se pone el foco sobre el desempeño de los modelos, se observará que, dejando de lado el modelo de *Nearest Neighbors* que se queda un poco rezagado, el resto posee un rendimiento similar. Por ejemplo, si se vuelve sobre la **curva de precision-recall** (que es la que nos interesa), se verá que la **precisión promedio (AP)** oscila entre el 81% y el 85%. Es decir, que utilizando un modelo complejo (tal como *Neural Net* o *AdaBoost*) apenas se logra una mejora del 4% sobre un modelo clásico como es *RBF SVM*. \n",
    "\n",
    "Por supuesto que los modelos aún se puede mejorar su rendimiento haciendo un trabajo de optimización de los hiperparámetros. Sin embargo, esta evaluación muestra una tendencia de su comportamiento y ofrece información para seleccionar uno (que luego puede ser mejorado optimizando los hiperparámetros). Teniendo en cuenta que el problema aquí planteado busca obtener *insights* del modelo que puedan ser de utilidad para el negocio, se opta por un clasificador basado en *AdaBoost* y entrenado con un dataset **balanceado**. *AdaBoost*, una vez entrenado, permite ver de forma sencilla que prioridad le asigna a los *features* para poder tomar decisiones. Mientras que en un modelo de *Neural Network* (que es el otro modelo que obtuvo mejores resultados), obtener dicha información sobre los *features* es más complejo porque requiere analizar el comportamiento interno de la red y sus conexiones (tarea que puede derivar en un dolor de cabeza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_reporte_clasificador(clf, X_test, y_test, df_resultados, dataset_utilizado, name):\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=['no payment', 'payment'], output_dict=True)\n",
    "\n",
    "    df_resultados = df_resultados.append({'clasificador' : name,\n",
    "                                 'dataset_utilizado': dataset_utilizado,\n",
    "                                 'precision_no_payment':report['no payment']['precision'],\n",
    "                                 'recall_no_payment':report['no payment']['recall'],\n",
    "                                 'f1-score_no_payment':report['no payment']['f1-score'],\n",
    "                                 'precision_payment':report['payment']['precision'],\n",
    "                                 'recall_payment':report['payment']['recall'],\n",
    "                                 'f1-score_payment':report['payment']['f1-score']}, \n",
    "                       ignore_index=True)\n",
    "    \n",
    "    return df_resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Defino un dataframe donde guardar los resultados\n",
    "df_resultados = pd.DataFrame({'clasificador' : [],\n",
    "                             'dataset_utilizado': [],\n",
    "                             'precision_no_payment':[],\n",
    "                             'recall_no_payment':[],\n",
    "                             'f1-score_no_payment':[],\n",
    "                             'precision_payment':[],\n",
    "                             'recall_payment':[],\n",
    "                             'f1-score_payment':[]})\n",
    "\n",
    "#Obtenemos los resultados para los modelos entrenados con el dataset desbalanceado\n",
    "for name, clf in zip(names_des, classifiers_des):\n",
    "    df_resultados = get_reporte_clasificador(clf, X_test_des, y_test_des, df_resultados, 'desbalanceado', name)\n",
    "    \n",
    "#Obtenemos los resultados para los modelos entrenados con el dataset desbalanceado\n",
    "for name, clf in zip(names_bal, classifiers_bal):\n",
    "    df_resultados = get_reporte_clasificador(clf, X_test_bal, y_test_bal, df_resultados, 'balanceado', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
