{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento datos Tiendanube\n",
    "\n",
    "Esta notebook se encarga de preprocesar los datos con el fin de que puedan ser utilizados para el entrenamiento de un modelo predictivo (clasificador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('test_data.csv', delimiter=';', index_col=0)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización de las variables numericas\n",
    "\n",
    "El objetivo es aplicar una técnia de normalización sobre las variables numéricas para que todas ellas se muevan en el mismo rango [0;1]\n",
    "\n",
    "Las variables a normalizar son:\n",
    "\n",
    "* **total_events_on_iOS**: registro de la cantidad de eventos que tuvo el trial por un dispositivo con sistema operativo Android\n",
    "* **total_events_on_Web**: registro de la cantidad de eventos que tuvo el trial por una computadora\n",
    "* **total_events_on_Android**: registro de la cantidad de eventos que tuvo el trial por un dispositivo con sistema operativo iOS\n",
    "* **admin_visits**: cantidad de visitas que registró el administrador \n",
    "* **intercom_conversations**: cantidad de conversaciones que registró la tienda con el equipo de soporte\n",
    "* **products_with_description**: cantidad de productos que poseen descripción \n",
    "* **total_products_with_images**: cantidad de productos que poseen imagen\n",
    "* **total_product_categories**: cantidad de categorías de productos creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Creamos un objeto escalador min-max\n",
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos las variables a normarlizar\n",
    "columnas_a_normalizar = [ \n",
    "    'admin_visits',\n",
    "    'intercom_conversations',\n",
    "    'products_with_description',\n",
    "    'total_products_with_images',\n",
    "    'total_product_categories',\n",
    "    'total_events_on_Android',\n",
    "    'total_events_on_Web',\n",
    "    'total_events_on_iOS',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un dataset auxiliar\n",
    "df_data_numerica_norm = df_data[columnas_a_normalizar]\n",
    "df_data_numerica_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamos los datos\n",
    "df_data_numerica_norm = pd.DataFrame(min_max_scaler.fit_transform(df_data_numerica_norm), columns=df_data_numerica_norm.columns)\n",
    "df_data_numerica_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoder para variables categoricas\n",
    "\n",
    "Para las variables categóricas se aplica la técnica de *One Hot Encoder* que permite mapear a las variables categóricas en un vector booleano.\n",
    "\n",
    "Las variables a mapear son:\n",
    "\n",
    "* **country**: país de origen del trial\n",
    "* **creation_platform**: plataforma por la cual se creó la tienda \n",
    "* **source_pulido**: origen de la tienda por campaña de marketing\n",
    "* **creation_weekday**: día de la semana en que se creó la tienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_categoricas =['country', 'creation_platform', 'source_pulido', 'creation_weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_categorica = df_data[columnas_categoricas]\n",
    "df_data_categorica['creation_weekday'] = df_data_categorica['creation_weekday'].apply(lambda x : str(x))\n",
    "df_data_categorica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_categorica =pd.get_dummies(df_data_categorica, prefix=columnas_categoricas)\n",
    "df_data_categorica.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenar las variables\n",
    "\n",
    "A continuación se unen las ambos tipos de variables en un solo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado = pd.concat([df_data_numerica_norm, df_data_categorica], axis=1)\n",
    "df_procesado['target'] = df_data['target'] \n",
    "df_procesado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado.to_csv('data_procesada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se extrae una muestra representativa con el fin de poder entrenar y analizar rápidamente diversos tipos de **clasificadores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_procesado.sample(frac=0.2)\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.countplot(x='target', data=df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv('dataset_desbalanceado.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset balanceado\n",
    "\n",
    "Dado que se trata de una dataset desbalanceado hacia la **clase 0** (es decir, aquellos usuarios que no se pasarán a *payment*), a continuación se genera un dataset equilibrado descartando instancias de la **clase 0** (pero tratando de mantener las particularidades de dicha clase). \n",
    "\n",
    "Esta estrategia, si bien implica no aprovechar el total de datos disponibles, permite equilibrar el dataset en favor de la **clase 1** (es decir, aquellos usuarios que se pasarán a *payment*) que es nuestra clase de interés. De esta manera los clasificadores entrenados no se dejarán influenciar por la tendencia del dataset original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, dividimos el dataframe en dos: uno para la **clase 0** y otro para la **clase 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positivo = df_procesado[df_procesado['target'] == 1]\n",
    "df_positivo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negativo = df_procesado[df_procesado['target'] == 0]\n",
    "df_negativo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se toma una muestra de dataframe de la **clase 0** que tenga un tamaño similar al dataframe de la **clase 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases_positivas = df_positivo.shape[0]\n",
    "clases_positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negativo_muestra = df_negativo.sample(n= (clases_positivas + int(clases_positivas*0.1)))\n",
    "df_negativo_muestra.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalemente se unen en un solo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanceado = pd.concat([df_positivo, df_negativo_muestra])\n",
    "df_balanceado = df_balanceado.sort_index()\n",
    "df_balanceado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.countplot(x='target', data=df_balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanceado.to_csv('dataset_balanceado.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
